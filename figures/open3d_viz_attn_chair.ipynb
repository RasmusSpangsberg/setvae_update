{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ShapeNet-Chair Attention Visualization\n",
    "- By running this script, you can get images of attention-based-color-coded pointclouds.\n",
    "## To run this code...\n",
    "- You should prepare the summary file by running sample_and_summarize.py with a trained checkpoint.\n",
    "- **You should prepare a DISPLAY to use open3d.**\n",
    "- You should install below libraries.\n",
    "    - matplotlib\n",
    "    - open3d\n",
    "    - numpy\n",
    "    - torch\n",
    "    - torchvision\n",
    "    - tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import open3d as o3d\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "torch.no_grad()\n",
    "from torchvision.utils import save_image, make_grid\n",
    "\n",
    "from draw import draw, draw_attention_open3d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set directories\n",
    "1. summary file path: summary_name\n",
    "2. path to save images: save_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = 'images_attn'\n",
    "experiment_name = 'shapenet15k-chair/camera-ready'\n",
    "summary_name = os.path.join('../checkpoints/gen/', experiment_name, 'summary.pth')\n",
    "summary_train_name = os.path.join('../checkpoints/gen/', experiment_name, 'summary_train_recon.pth')\n",
    "\n",
    "imgdir = os.path.join(save_dir, experiment_name)\n",
    "imgdir_recon = os.path.join(imgdir, 'recon')\n",
    "imgdir_gt = os.path.join(imgdir, 'gt')\n",
    "imgdir_gen = os.path.join(imgdir, 'gen')\n",
    "imgdir_gt_train = os.path.join(imgdir, 'gt_train')\n",
    "\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "os.makedirs(imgdir_gt, exist_ok=True)\n",
    "os.makedirs(imgdir_recon, exist_ok=True)\n",
    "os.makedirs(imgdir_gen, exist_ok=True)\n",
    "os.makedirs(imgdir_gt_train, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation and generated\n",
    "summary = torch.load(summary_name)\n",
    "for k, v in summary.items():\n",
    "    try:\n",
    "        print(f\"{k}: {v.shape}\")\n",
    "    except AttributeError:\n",
    "        print(f\"{k}: {len(v)}\")\n",
    "len_att = len(summary['dec_att'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "summary_train = torch.load(summary_train_name)\n",
    "for k, v in summary_train.items():\n",
    "    try:\n",
    "        print(f\"{k}: {v.shape}\")\n",
    "    except AttributeError:\n",
    "        print(f\"{k}: {len(v)}\")\n",
    "len_att_train = len(summary_train['dec_att'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select the samples to visualize\n",
    "- parse the samples by index.\n",
    "- below default code will visualize all samples. **Warning: Requires Huge Memory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_targets = list(range(len(summary['gt_mask'])))[:]\n",
    "gen_targets = list(range(len(summary['smp_mask'])))[:]\n",
    "\n",
    "gt = summary['gt_set'][recon_targets]\n",
    "gt_mask = summary['gt_mask'][recon_targets]\n",
    "\n",
    "recon = summary['recon_set'][recon_targets]\n",
    "recon_mask = summary['recon_mask'][recon_targets]\n",
    "\n",
    "dec_att = [summary['dec_att'][l][:, :, recon_targets] for l in range(len_att)]\n",
    "enc_att = [summary['enc_att'][l][:, :, recon_targets] for l in range(len_att)]\n",
    "\n",
    "gen = summary['smp_set'][gen_targets]\n",
    "gen_mask = summary['smp_mask'][gen_targets]\n",
    "gen_att = [summary['smp_att'][l][:, :, gen_targets] for l in range(len_att)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_targets_train = list(range(len(summary_train['gt_mask'])))[:]\n",
    "\n",
    "gt_train = summary_train['gt_set'][recon_targets_train]\n",
    "gt_mask_train = summary_train['gt_mask'][recon_targets_train]\n",
    "enc_att_train = [summary_train['enc_att'][l][:, :, recon_targets_train] for l in range(len_att_train)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Attention\n",
    "- lidx: index of layer\n",
    "- projection: ISAB has 2 projection attention and back-projection attention.\n",
    "    - 0: projection, 1: back-projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention_selector(gt, gt_mask, att, lidx=0, projection=0, selected_heads=None, palette_permutation=None):\n",
    "    if selected_heads is not None:\n",
    "        att = [a[:, selected_heads].view(a.size(0), len(selected_heads), a.size(2), a.size(3), a.size(4)) for a in att]\n",
    "    return draw_attention_open3d(gt, gt_mask, att[lidx][projection], color_opt='gist_rainbow', size=10, palette_permutation=palette_permutation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Encoder Attention on GT samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for topdown in tqdm(range(2,5)):\n",
    "    for projection in [0]:\n",
    "        if topdown == 2:\n",
    "            selected_heads = [3]\n",
    "            palette_permutation = None\n",
    "        elif topdown == 3:\n",
    "            selected_heads = [3]\n",
    "            palette_permutation = [0, 1, 3, 2]\n",
    "        elif topdown == 4:\n",
    "            selected_heads = [0]\n",
    "            palette_permutation = None\n",
    "        else:\n",
    "            selected_heads = list(range(enc_att[0].size(1)))\n",
    "            palette_permutation = None\n",
    "        print(f\"HEAD: {selected_heads}, COLOR: {palette_permutation}\")\n",
    "        gt_imgs = attention_selector(gt, gt_mask, enc_att, len(enc_att) - 1 - topdown, projection,\n",
    "                                     selected_heads=selected_heads, palette_permutation=palette_permutation)\n",
    "        for head_idx in range(len(selected_heads)):\n",
    "            for idx in range(len(recon_targets)):\n",
    "                data_idx = recon_targets[idx]\n",
    "                try:\n",
    "                    pos_min = torch.nonzero(gt_imgs[idx][head_idx].mean(0) != 1).min(0)[0]\n",
    "                    pos_max = torch.nonzero(gt_imgs[idx][head_idx].mean(0) != 1).max(0)[0]\n",
    "                    gt_img = gt_imgs[idx][head_idx][:, pos_min[0]:pos_max[0]+1, pos_min[1]:pos_max[1]+1]\n",
    "                except RuntimeError:\n",
    "                    gt_img = gt_imgs[idx][head_idx]\n",
    "                head = selected_heads[head_idx]\n",
    "                save_image(gt_img, os.path.join(imgdir_gt, f'{topdown}_{projection}_{head}_{data_idx}.png'))\n",
    "        del gt_imgs\n",
    "print('gt DONE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Decoder Attention on Generated samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for topdown in tqdm(range(2, 5)):\n",
    "    for projection in [1]:\n",
    "        if topdown == 2:\n",
    "            selected_heads = [3]\n",
    "            palette_permutation = [1, 0]\n",
    "        elif topdown == 3:\n",
    "            selected_heads = [2]\n",
    "            palette_permutation = [1, 0, 3, 2]\n",
    "        elif topdown == 4:\n",
    "            selected_heads = [2]\n",
    "            palette_permutation = None\n",
    "        else:\n",
    "            selected_heads = list(range(gen_att[0].size(1)))\n",
    "            palette_permutation = None\n",
    "        print(f\"HEAD: {selected_heads}, COLOR: {palette_permutation}\")\n",
    "        gen_imgs = attention_selector(gen, gen_mask, gen_att, topdown, projection, selected_heads, palette_permutation)\n",
    "        for head_idx in range(len(selected_heads)):\n",
    "            for idx in range(len(gen_targets)):\n",
    "                data_idx = gen_targets[idx]\n",
    "                try:\n",
    "                    pos_min = torch.nonzero(gen_imgs[idx][head_idx].mean(0) != 1).min(0)[0]\n",
    "                    pos_max = torch.nonzero(gen_imgs[idx][head_idx].mean(0) != 1).max(0)[0]\n",
    "                    gen_img = gen_imgs[idx][head_idx][:, pos_min[0]:pos_max[0]+1, pos_min[1]:pos_max[1]+1]\n",
    "                except RuntimeError:\n",
    "                    gen_img = gen_imgs[idx][head_idx]\n",
    "                head = selected_heads[head_idx]\n",
    "                save_image(gen_img.float(), os.path.join(imgdir_gen, f'{topdown}_{projection}_{head}_{data_idx}.png'))\n",
    "        del gen_imgs\n",
    "print('gen DONE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Encoder Attention on Train GT Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for topdown in tqdm(range(2, 5)):\n",
    "    for projection in [0]:\n",
    "        if topdown == 2:\n",
    "            selected_heads = [3]\n",
    "            palette_permutation = None\n",
    "        elif topdown == 3:\n",
    "            selected_heads = [3]\n",
    "            palette_permutation = [0, 1, 3, 2]\n",
    "        elif topdown == 4:\n",
    "            selected_heads = [0]\n",
    "            palette_permutation = None\n",
    "        else:\n",
    "            selected_heads = list(range(enc_att[0].size(1)))\n",
    "            palette_permutation = None\n",
    "        print(f\"HEAD: {selected_heads}, COLOR: {palette_permutation}\")\n",
    "        gt_imgs = attention_selector(gt_train, gt_mask_train, enc_att_train, len(enc_att_train) - 1 - topdown, projection,\n",
    "                                     selected_heads=selected_heads, palette_permutation=palette_permutation)\n",
    "        for head_idx in range(len(selected_heads)):\n",
    "            for idx in range(len(recon_targets_train)):\n",
    "                data_idx = recon_targets_train[idx]\n",
    "                try:\n",
    "                    pos_min = torch.nonzero(gt_imgs[idx][head_idx].mean(0) != 1).min(0)[0]\n",
    "                    pos_max = torch.nonzero(gt_imgs[idx][head_idx].mean(0) != 1).max(0)[0]\n",
    "                    gt_img = gt_imgs[idx][head_idx][:, pos_min[0]:pos_max[0]+1, pos_min[1]:pos_max[1]+1]\n",
    "                except RuntimeError:\n",
    "                    gt_img = gt_imgs[idx][head_idx]\n",
    "                head = selected_heads[head_idx]\n",
    "                save_image(gt_img, os.path.join(imgdir_gt_train, f'{topdown}_{projection}_{head}_{data_idx}.png'))\n",
    "        del gt_imgs\n",
    "print('gt DONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
