{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cardinality-Generalization Visualization\n",
    "- To run this code, you need summary.pth and the corresponding model checkpoint *.pt file.\n",
    "- This code will use GPU:0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from argparse import Namespace\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from draw import draw, draw_attention, draw_open3d\n",
    "\n",
    "import sys,inspect\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0,parentdir) \n",
    "from models.networks import SetVAE\n",
    "from args import get_parser\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='0'\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose Directory and Model\n",
    "- save_dir: directory to save images\n",
    "- experiment_name: directory with summary.pth, and *.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = 'images_cardinality_generalization_final'\n",
    "experiment_name = 'shapenet15k-car/camera-ready'\n",
    "summary_name = os.path.join('../checkpoints/gen/', experiment_name, 'summary.pth')\n",
    "checkpoint_name = sorted(glob(os.path.join('../checkpoints/gen/', experiment_name, '*.pt')))[-1]\n",
    "print(checkpoint_name)\n",
    "\n",
    "imgdir = os.path.join(save_dir, experiment_name)\n",
    "imgdir_gt = os.path.join(imgdir, 'gt')\n",
    "imgdir_recon = os.path.join(imgdir, 'recon')\n",
    "imgdir_gen = os.path.join(imgdir, 'gen')\n",
    "\n",
    "os.makedirs(imgdir_gt, exist_ok=True)\n",
    "os.makedirs(imgdir_recon, exist_ok=True)\n",
    "os.makedirs(imgdir_gen, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Summary file to use fixed latents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = torch.load(summary_name)\n",
    "for k, v in summary.items():\n",
    "    try:\n",
    "        print(f\"{k}: {v.shape}\")\n",
    "    except AttributeError:\n",
    "        print(f\"{k}: {len(v)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select your model configuration\n",
    "- If you use the configuration we provided, please select one from below based on your dataset type.\n",
    "- If you use your own customization, please make a configuration dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ShapeNet\n",
    "argsdict = {'input_dim': 3, 'max_outputs': 2500, 'init_dim': 32, 'n_mixtures': 4,\n",
    "            'z_dim': 16, 'z_scales': [1, 1, 2, 4, 8, 16, 32], 'hidden_dim': 64, 'num_heads': 4,\n",
    "            'fixed_gmm': True, 'train_gmm': True, 'slot_ln': False, 'slot_mlp': False,\n",
    "            'slot_att': True, 'ln': True, 'seed': 42,\n",
    "            'dataset_type': 'shapenet15k', 'num_workers': 4, 'eval': True,\n",
    "            'gpu': 0, 'batch_size': 32}\n",
    "args = get_parser().parse_args('')\n",
    "for k, v in argsdict.items():\n",
    "    setattr(args, k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MultiMNIST\n",
    "argsdict = {'input_dim': 2, 'max_outputs': 600, 'init_dim': 64, 'n_mixtures': 16,\n",
    "            'z_dim': 16, 'z_scales': [2, 4, 8, 16, 32], 'hidden_dim': 64, 'num_heads': 4,\n",
    "            'slot_att': True, 'ln': True, 'shared_ip': False, 'seed': 42,\n",
    "            'dataset_type': 'shapenet15k', 'num_workers': 4, 'eval': True,\n",
    "            'gpu': 0, 'batch_size': 32}\n",
    "\n",
    "args = get_parser().parse_args('')\n",
    "for k, v in argsdict.items():\n",
    "    setattr(args, k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST\n",
    "argsdict = {'input_dim': 2, 'max_outputs': 400, 'init_dim': 32, 'n_mixtures': 4,\n",
    "            'z_dim': 16, 'z_scales': [2, 4, 8, 16, 32], 'hidden_dim': 64, 'num_heads': 4,\n",
    "            'slot_att': True, 'ln': True, 'seed': 42,\n",
    "            'dataset_type': 'mnist', 'num_workers': 4, 'eval': True,\n",
    "            'gpu': 0, 'batch_size': 32}\n",
    "\n",
    "args = get_parser().parse_args('')\n",
    "for k, v in argsdict.items():\n",
    "    setattr(args, k, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SetVAE(args)\n",
    "checkpoint = torch.load(checkpoint_name, map_location=torch.device('cpu'))\n",
    "model.load_state_dict(checkpoint['model'], strict=True)\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "n_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "n_gen_parameters = sum(p.numel() for p in model.decoder.parameters() if p.requires_grad)\n",
    "print(f\"Full: {n_parameters}, Gen: {n_gen_parameters}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = summary['smp_set']\n",
    "gen_mask = summary['smp_mask']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cardinality Generalization\n",
    "- Define the cardinalities you want to visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cardinality = torch.tensor([100, 500, 2048, 3000, 10000, 100000])\n",
    "\n",
    "cardinality = cardinality.to(device)\n",
    "max_outputs = cardinality.max().item()\n",
    "model.max_outputs = max_outputs\n",
    "model.init_set.max_outputs = max_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def generate_all(gen_idx, cardinality):\n",
    "    z = [prior[gen_idx:gen_idx+1].repeat(cardinality.size(0), 1, 1).to(device) for prior in summary['priors']]\n",
    "    output = model.sample(cardinality, given_latents=z)\n",
    "    \n",
    "    gen_imgs = draw(output['set'], output['set_mask'])\n",
    "    return gen_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for gen_idx in tqdm(gen_targets):\n",
    "    gen_imgs = generate_all(gen_idx, cardinality)\n",
    "    \n",
    "    # Check whether the dataset is MNIST or ShapeNet.\n",
    "    if gen_imgs.dtype == torch.float32:\n",
    "        # Below code snippet crop the image's white margins. (only for ShapeNet)\n",
    "        try:\n",
    "            pos_min = torch.nonzero(gen_imgs.mean(0).mean(0) != 1).min(0)[0]\n",
    "            pos_max = torch.nonzero(gen_imgs.mean(0).mean(0) != 1).max(0)[0]\n",
    "            gen_imgs = gen_imgs[:, :, pos_min[0]:pos_max[0]+1, pos_min[1]:pos_max[1]+1]\n",
    "        except RuntimeError:\n",
    "            pass\n",
    "        \n",
    "    for imgs, c in zip(gen_imgs, cardinality):\n",
    "        if imgs.dtype == torch.uint8:\n",
    "            imgs = imgs.float() / 255.            \n",
    "        save_image(imgs[2], os.path.join(imgdir_gen, f'{gen_idx}_{c}.png'))\n",
    "    del gen_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Everything saved under {imgdir}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
